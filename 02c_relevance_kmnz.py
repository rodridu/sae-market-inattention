"""
Phase 2c: KMNZ Relevance Computation (R_fdt)
Learns sentence-level importance from market reactions using attention-based model.

Based on Kim-Muhn-Nikolaev-Zhang framework:
- Embed all sentences in a filing
- Pass through transformer with attention layers
- Train to predict announcement returns and EPS surprises
- Extract attention weights as sentence-level relevance scores

Proposal alignment (Section 4.3):
For each sentence s in filing d:
  R_fdt = attention_weight_s
where attention weights come from return-supervised transformer

This is a FRAMEWORK IMPLEMENTATION with placeholders for:
1. Sentence-sequence transformer architecture
2. Return-supervised training
3. Attention weight extraction

Full implementation requires:
- Announcement return data (CAR[-1,+1], longer windows)
- Analyst forecast data for EPS surprises
- GPU resources for transformer training
"""

import os
import pandas as pd
import numpy as np
from pathlib import Path
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# Optional: uncomment when implementing full KMNZ approach
# import torch
# import torch.nn as nn
# from torch.utils.data import Dataset, DataLoader

# ============================================
# Configuration
# ============================================

DATA_DIR = Path(r"C:\Users\ofs4963\Dropbox\Arojects\SAE\data")
OUTPUT_DIR = DATA_DIR

# Use SAE training sample for development
SENTENCE_FILE = DATA_DIR / "sentences_sampled.parquet"
EMBEDDING_FILE = DATA_DIR / "sentence_embeddings.npz"
RELEVANCE_OUTPUT = DATA_DIR / "relevance_kmnz_sae.parquet"

# KMNZ parameters
HIDDEN_DIM = 256
NUM_HEADS = 4
NUM_LAYERS = 2
MAX_SENTENCES = 512  # Maximum sentences per document

# ============================================
# 1. Load Outcome Data (Returns, EPS)
# ============================================

def load_announcement_returns(sent_df):
    """
    Load announcement returns for each filing.

    For full KMNZ implementation, this would:
    1. Query CRSP for CAR[-1,+1] around filing announcement
    2. Query I/B/E/S for EPS surprises
    3. Merge with sent_df on (cik, year) or accession_number

    Args:
        sent_df: DataFrame with sentences

    Returns:
        DataFrame with returns and EPS for each document
    """
    # PLACEHOLDER: In production, query CRSP/Compustat/I/B/E/S
    # Example query:
    # SELECT cik, year, car_1_1, eps_surprise
    # FROM announcement_returns
    # WHERE (cik, year) IN (SELECT DISTINCT cik, year FROM sent_df)

    # For now, create random outcomes
    print("   WARNING: Using random returns (placeholder)")

    unique_docs = sent_df[['accession_number', 'cik', 'year']].drop_duplicates()
    unique_docs['car_1_1'] = np.random.randn(len(unique_docs)) * 0.05
    unique_docs['eps_surprise'] = np.random.randn(len(unique_docs)) * 0.02

    return unique_docs

# ============================================
# 2. Attention-Based Relevance Model
# ============================================

class KMNZRelevanceModel:
    """
    Attention-based transformer for learning sentence relevance.

    Architecture:
    - Input: sequence of sentence embeddings for a document
    - Transformer encoder with multi-head attention
    - Pooling layer (attention-weighted sum)
    - Prediction head for returns / EPS

    Training:
    - Supervised loss: MSE on returns and EPS
    - Extract attention weights as relevance scores
    """

    def __init__(self, input_dim=384, hidden_dim=HIDDEN_DIM,
                 num_heads=NUM_HEADS, num_layers=NUM_LAYERS):
        """
        Initialize KMNZ model.

        Args:
            input_dim: Embedding dimension
            hidden_dim: Hidden layer dimension
            num_heads: Number of attention heads
            num_layers: Number of transformer layers
        """
        # PLACEHOLDER: Full implementation would use PyTorch
        #
        # self.embedding_proj = nn.Linear(input_dim, hidden_dim)
        # encoder_layer = nn.TransformerEncoderLayer(
        #     d_model=hidden_dim,
        #     nhead=num_heads,
        #     batch_first=True
        # )
        # self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        #
        # # Attention pooling layer
        # self.attention = nn.Linear(hidden_dim, 1)
        #
        # # Prediction heads
        # self.return_head = nn.Linear(hidden_dim, 1)
        # self.eps_head = nn.Linear(hidden_dim, 1)

        print(f"   KMNZ Model: {num_layers} layers, {num_heads} heads, {hidden_dim} hidden dim")
        print("   NOTE: This is a placeholder. Implement with PyTorch for production.")

        self.input_dim = input_dim
        self.hidden_dim = hidden_dim

    def forward(self, sentence_embeddings):
        """
        Forward pass to compute attention weights and predictions.

        Args:
            sentence_embeddings: (batch, n_sentences, input_dim)

        Returns:
            attention_weights: (batch, n_sentences)
            return_pred: (batch, 1)
            eps_pred: (batch, 1)
        """
        # PLACEHOLDER: Full implementation
        #
        # x = self.embedding_proj(sentence_embeddings)  # (batch, n_sent, hidden)
        # x = self.transformer(x)  # (batch, n_sent, hidden)
        #
        # # Attention weights
        # attn_scores = self.attention(x).squeeze(-1)  # (batch, n_sent)
        # attn_weights = torch.softmax(attn_scores, dim=1)
        #
        # # Weighted pooling
        # doc_repr = (x * attn_weights.unsqueeze(-1)).sum(dim=1)  # (batch, hidden)
        #
        # # Predictions
        # return_pred = self.return_head(doc_repr)
        # eps_pred = self.eps_head(doc_repr)
        #
        # return attn_weights, return_pred, eps_pred

        # For now: return uniform attention (placeholder)
        batch_size, n_sent, _ = sentence_embeddings.shape
        uniform_attn = np.ones((batch_size, n_sent)) / n_sent
        return_pred = np.random.randn(batch_size, 1)
        eps_pred = np.random.randn(batch_size, 1)

        return uniform_attn, return_pred, eps_pred

    def train_model(self, train_loader, val_loader, epochs=10):
        """
        Train KMNZ model on returns and EPS.

        Args:
            train_loader: DataLoader with (embeddings, returns, eps)
            val_loader: Validation DataLoader
            epochs: Number of training epochs
        """
        # PLACEHOLDER: Full training loop
        #
        # optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)
        # criterion = nn.MSELoss()
        #
        # for epoch in range(epochs):
        #     for batch in train_loader:
        #         embeddings, returns, eps = batch
        #         attn_weights, return_pred, eps_pred = self.forward(embeddings)
        #
        #         loss = criterion(return_pred, returns) + criterion(eps_pred, eps)
        #         loss.backward()
        #         optimizer.step()
        #         optimizer.zero_grad()

        print(f"   Training for {epochs} epochs...")
        print("   NOTE: Full training loop not implemented (placeholder)")

# ============================================
# 3. Extract Relevance Scores
# ============================================

def extract_relevance_scores(model, sent_df, embeddings):
    """
    Extract sentence-level relevance scores from trained model.

    Args:
        model: Trained KMNZ model
        sent_df: DataFrame with sentences
        embeddings: Sentence embeddings

    Returns:
        DataFrame with added 'relevance_kmnz' column
    """
    print("\n   Extracting relevance scores...")

    relevance_scores = []

    # Group by document
    doc_groups = sent_df.groupby('accession_number')

    for accession_num, group in tqdm(doc_groups, desc="Documents"):
        # Get embeddings for this document
        indices = group.index.tolist()
        doc_embeddings = embeddings[indices]

        # Pad or truncate to MAX_SENTENCES
        if len(doc_embeddings) > MAX_SENTENCES:
            doc_embeddings = doc_embeddings[:MAX_SENTENCES]
        elif len(doc_embeddings) < MAX_SENTENCES:
            padding = np.zeros((MAX_SENTENCES - len(doc_embeddings), doc_embeddings.shape[1]))
            doc_embeddings = np.vstack([doc_embeddings, padding])

        # Forward pass to get attention weights
        doc_embeddings_batch = doc_embeddings[np.newaxis, :, :]  # (1, n_sent, dim)
        attn_weights, _, _ = model.forward(doc_embeddings_batch)
        attn_weights = attn_weights[0, :len(group)]  # Remove padding

        relevance_scores.extend(attn_weights.tolist())

    sent_df['relevance_kmnz'] = relevance_scores

    return sent_df

# ============================================
# 4. Simplified Relevance Proxy (Placeholder)
# ============================================

def compute_simple_relevance_proxy(sent_df):
    """
    Simplified relevance proxy using sentence position and content heuristics.

    KMNZ findings:
    - Early sentences (MD&A, Segment info) have high relevance
    - Governance/ESG boilerplate has low relevance
    - Numbers, financial terms indicate high relevance

    Args:
        sent_df: DataFrame with sentences

    Returns:
        DataFrame with added 'relevance_kmnz' column
    """
    print("   Method: Simplified proxy (position + content heuristics)")
    print("   NOTE: Replace with full KMNZ model for production")

    relevance_scores = []

    # Financial keywords (proxy for relevance)
    financial_keywords = {
        'revenue', 'revenues', 'sales', 'income', 'earnings', 'profit',
        'loss', 'cash', 'debt', 'assets', 'liabilities', 'equity',
        'segment', 'segments', 'operations', 'margin', 'ebitda',
        'goodwill', 'intangibles', 'impairment', 'acquisition'
    }

    for idx, row in tqdm(sent_df.iterrows(), total=len(sent_df), desc="Computing relevance"):
        # Position-based relevance (earlier = more relevant)
        position_score = np.exp(-row['sentence_id'] / 10)  # Decay with position

        # Content-based relevance
        words = set(str(row['text']).lower().split())
        keyword_count = len(words & financial_keywords)
        content_score = min(keyword_count / 5.0, 1.0)  # Cap at 1.0

        # Numbers (financial disclosures)
        n_numbers = sum(1 for w in str(row['text']).split() if any(c.isdigit() for c in w))
        number_score = min(n_numbers / 20.0, 1.0)

        # Item type (Item 7 MD&A typically most relevant)
        item_score = 1.0 if row['item_type'] == 'item7' else 0.7 if row['item_type'] == 'item1' else 0.5

        # Combine
        relevance = 0.3 * position_score + 0.3 * content_score + 0.2 * number_score + 0.2 * item_score

        relevance_scores.append(relevance)

    sent_df['relevance_kmnz'] = relevance_scores

    return sent_df

# ============================================
# Main Execution
# ============================================

def main(method="proxy"):
    """
    Main execution pipeline.

    Args:
        method: "kmnz" (full model) or "proxy" (simplified)
    """
    print("="*60)
    print("PHASE 2c: KMNZ RELEVANCE COMPUTATION")
    print("="*60)

    # Load sentence data
    print(f"\nLoading sentence data from {SENTENCE_FILE}...")
    sent_df = pd.read_parquet(SENTENCE_FILE)
    print(f"Loaded {len(sent_df):,} sentences")

    # Load embeddings
    print(f"Loading embeddings from {EMBEDDING_FILE}...")
    emb_data = np.load(EMBEDDING_FILE)
    embeddings = emb_data['embeddings']
    print(f"Loaded embeddings: {embeddings.shape}")

    if method == "kmnz":
        print("\n   Method: Full KMNZ (attention-based relevance)")
        print("   WARNING: This requires outcome data and substantial compute")

        # Load outcomes
        outcome_df = load_announcement_returns(sent_df)

        # Initialize model
        model = KMNZRelevanceModel(input_dim=embeddings.shape[1])

        # Train model (placeholder)
        model.train_model(None, None, epochs=10)

        # Extract relevance scores
        sent_df_with_relevance = extract_relevance_scores(model, sent_df, embeddings)

    elif method == "proxy":
        # Use simplified proxy
        sent_df_with_relevance = compute_simple_relevance_proxy(sent_df)

    else:
        raise ValueError(f"Unknown method: {method}")

    # Save
    RELEVANCE_OUTPUT.parent.mkdir(exist_ok=True, parents=True)
    sent_df_with_relevance.to_parquet(RELEVANCE_OUTPUT, index=False)
    print(f"\nâœ“ Saved relevance measures to {RELEVANCE_OUTPUT}")

    # Summary statistics
    print("\n" + "="*60)
    print("PHASE 2c COMPLETE")
    print("="*60)
    print(f"Sentences with relevance: {len(sent_df_with_relevance):,}")
    print(f"\nRelevance statistics:")
    print(sent_df_with_relevance['relevance_kmnz'].describe())

    if method == "proxy":
        print("\n" + "!"*60)
        print("IMPORTANT: Current implementation uses simplified proxy")
        print("For production research:")
        print("  1. Collect announcement return data (CRSP)")
        print("  2. Collect analyst forecast data (I/B/E/S)")
        print("  3. Implement attention-based transformer")
        print("  4. Train model to predict returns/EPS")
        print("  5. Extract attention weights as relevance")
        print("!"*60)

    print(f"\nNext steps:")
    print(f"  - Run 03_sae_training.py with CLN novelty and KMNZ relevance")

    return sent_df_with_relevance

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Compute KMNZ relevance measures')
    parser.add_argument('--method', default='proxy', choices=['kmnz', 'proxy'],
                        help='Method: "kmnz" for full implementation, "proxy" for simplified')
    args = parser.parse_args()

    sent_df_with_relevance = main(method=args.method)
